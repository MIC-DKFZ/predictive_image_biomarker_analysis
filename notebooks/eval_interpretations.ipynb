{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe1afa01-f6b6-4098-8101-03fa0c663313",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Model Interpretations of Treatment Effect Estimation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b15a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "os.chdir(Path(os.getcwd()).parents[0])\n",
    "os.getcwd()\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import math\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from predimgbmanalysis.eval_biomarkers import *\n",
    "\n",
    "from predimgbmanalysis.train import ToyModelImgModule\n",
    "from predimgbmanalysis.get_toydata import CUB2011, ISIC2018\n",
    "import scipy\n",
    "\n",
    "import yaml\n",
    "\n",
    "import tqdm.notebook as tq\n",
    "import time\n",
    "\n",
    "from torch import nn\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.model_targets import (\n",
    "    ClassifierOutputTarget,\n",
    "    RawScoresOutputTarget,\n",
    ")\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "from captum.attr import (\n",
    "    GradientShap,\n",
    "    GuidedGradCam,\n",
    "    GradientShap,\n",
    "    GuidedBackprop,\n",
    "    NoiseTunnel,\n",
    "    IntegratedGradients,\n",
    ")\n",
    "from captum.attr import visualization as vis\n",
    "from gradcam3D import GradCAM3D\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "heat_cmap = LinearSegmentedColormap.from_list(\n",
    "    \"heatmap attribution\", [(0, \"#FF0051\"), (0.5, \"#ffffff\"), (1, \"#008BFB\")], N=256\n",
    ")\n",
    "\n",
    "abs_cmap = LinearSegmentedColormap.from_list(\n",
    "    \"absolute attribution\", [(0, \"#ffffff\"), (1, \"#8F37BB\")], N=256\n",
    ")\n",
    "\n",
    "\n",
    "class TwoHead_Wrapper(nn.Module):\n",
    "\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.model(input)\n",
    "        output = torch.hstack(list(output))\n",
    "        return output\n",
    "\n",
    "\n",
    "class CATE_Wrapper(nn.Module):\n",
    "    # difference of two heads\n",
    "\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.model(input)\n",
    "        return output[1] - output[0]\n",
    "\n",
    "\n",
    "def normalize_pos_zero(data):\n",
    "    return (data - data.min()) / ((data.max() - data.min()) + 0.00000000001)\n",
    "\n",
    "\n",
    "def normalize_pos_neg(data):\n",
    "    \"\"\"\n",
    "    Normalize a PyTorch tensor of data to the range of -1 to 1.\n",
    "    Negative values will be normalized between -1 and 0, and positive values between 0 and 1.\n",
    "\n",
    "    Parameters:\n",
    "    - data: A PyTorch tensor of numerical values.\n",
    "\n",
    "    Returns:\n",
    "    - A PyTorch tensor where negative values are normalized to [-1, 0] and positive values to [0, 1].\n",
    "    \"\"\"\n",
    "    # Handle negative values\n",
    "    negative_mask = data < 0\n",
    "    negative_data = data[negative_mask]\n",
    "    if negative_data.nelement() > 0:\n",
    "        neg_min = torch.min(negative_data)\n",
    "        neg_max = torch.max(negative_data)\n",
    "        # Avoid division by zero\n",
    "        if neg_min != neg_max:\n",
    "            normalized_negative_data = (negative_data - neg_min) / (\n",
    "                neg_max - neg_min\n",
    "            ) - 1\n",
    "        else:\n",
    "            normalized_negative_data = torch.full_like(\n",
    "                negative_data, -0.5\n",
    "            )  # Arbitrary choice when all values are equal\n",
    "        data[negative_mask] = normalized_negative_data\n",
    "\n",
    "    # Handle positive values\n",
    "    positive_mask = data > 0\n",
    "    positive_data = data[positive_mask]\n",
    "    if positive_data.nelement() > 0:\n",
    "        pos_min = torch.min(positive_data)\n",
    "        pos_max = torch.max(positive_data)\n",
    "        # Avoid division by zero\n",
    "        if pos_min != pos_max:\n",
    "            normalized_positive_data = (positive_data - pos_min) / (pos_max - pos_min)\n",
    "        else:\n",
    "            normalized_positive_data = torch.full_like(\n",
    "                positive_data, 0.5\n",
    "            )  # Arbitrary choice when all values are equal\n",
    "        data[positive_mask] = normalized_positive_data\n",
    "\n",
    "    return data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b64e85f7",
   "metadata": {},
   "source": [
    "### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24fc21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_drive_path = os.getenv(\"DATASET_LOCATION\", \"/absolute/path/to/datasets\")\n",
    "\n",
    "dataset_root = {\n",
    "    \"CMNIST\": os.path.join(network_drive_path, \"\"),\n",
    "    \"cub\": os.path.join(network_drive_path, \"CUB_200_2011\"),\n",
    "    \"isic\": os.path.join(network_drive_path, \"ISIC2018\"),\n",
    "    \"lungCT\": os.path.join(network_drive_path, \"NSCLC_Radiomics\"),  \n",
    "}\n",
    "\n",
    "experiments = os.getenv(\"EPXERIMENTS_LOCATION\", \"/absolute/path/to/experiments\")\n",
    "experiment_dirs = {\n",
    "    \"CMNIST_a\": os.path.join(\n",
    "        experiments, \"2022-10-25_toymodel_miniresnetmtl_cmnist3a_02\"\n",
    "    ),\n",
    "    \"CMNIST_b\": os.path.join(\n",
    "        experiments, \"2022-10-25_toymodel_miniresnetmtl_cmnist3b_02\"\n",
    "    ),\n",
    "    \"CMNISTvline_a\": os.path.join(\n",
    "        experiments, \"2022-10-31_toymodel_miniresnetmtl_cmnist5a\"\n",
    "    ),\n",
    "    \"CMNISTvline_b\": os.path.join(\n",
    "        experiments, \"2022-10-31_toymodel_miniresnetmtl_cmnist5b\"\n",
    "    ),\n",
    "    \"cub_a\": os.path.join(\n",
    "        experiments, \"2022-10-27_toymodel_resnet18mtl_cub2011allclassesa_01\"\n",
    "    ),\n",
    "    \"cub_b\": os.path.join(\n",
    "        experiments, \"2022-10-27_toymodel_resnet18mtl_cub2011allclassesb_01\"\n",
    "    ),\n",
    "    \"isic_a\": os.path.join(\n",
    "        experiments, \"2022-10-19_toymodel_resnet18mtl_isic2018a_binary\"\n",
    "    ),\n",
    "    \"isic_b\": os.path.join(\n",
    "        experiments, \"2022-10-19_toymodel_resnet18mtl_isic2018b_binary\"\n",
    "    ),\n",
    "    \"isic_a_newarch\": os.path.join(\n",
    "        experiments, \"2022-10-28_toymodel_resnet18mtl_isic2018a_binary_05\"\n",
    "    ),\n",
    "    \"isic_b_newarch\": os.path.join(\n",
    "        experiments, \"2022-10-28_toymodel_resnet18mtl_isic2018b_binary_05\"\n",
    "    ),\n",
    "    \"lungCT_a_fold0\": os.path.join(\n",
    "        experiments,\n",
    "        \"test_nsclctumourpatchesnnunet_linear_zscore_mtl4fc_a_extendedrandtransformnew_fold0_complete\",\n",
    "    ),\n",
    "    \"lungCT_a_fold1\": os.path.join(\n",
    "        experiments,\n",
    "        \"test_nsclctumourpatchesnnunet_linear_zscore_mtl4fc_a_extendedrandtransformnew_fold1_complete\",\n",
    "    ),\n",
    "    \"lungCT_a_fold2\": os.path.join(\n",
    "        experiments,\n",
    "        \"test_nsclctumourpatchesnnunet_linear_zscore_mtl4fc_a_extendedrandtransformnew_fold2_complete\",\n",
    "    ),\n",
    "    \"lungCT_a_fold3\": os.path.join(\n",
    "        experiments,\n",
    "        \"test_nsclctumourpatchesnnunet_linear_zscore_mtl4fc_a_extendedrandtransformnew_fold3_complete\",\n",
    "    ),\n",
    "    \"lungCT_a_fold4\": os.path.join(\n",
    "        experiments,\n",
    "        \"test_nsclctumourpatchesnnunet_linear_zscore_mtl4fc_a_extendedrandtransformnew_fold4_complete\",\n",
    "    ),\n",
    "    \"lungCT_b_fold0\": os.path.join(\n",
    "        experiments,\n",
    "        \"test_nsclctumourpatchesnnunet_linear_zscore_mtl4fc_b_extendedrandtransformnew_fold0_complete\",\n",
    "    ),\n",
    "    \"lungCT_b_fold1\": os.path.join(\n",
    "        experiments,\n",
    "        \"test_nsclctumourpatchesnnunet_linear_zscore_mtl4fc_b_extendedrandtransformnew_fold1_complete\",\n",
    "    ),\n",
    "    \"lungCT_b_fold2\": os.path.join(\n",
    "        experiments,\n",
    "        \"test_nsclctumourpatchesnnunet_linear_zscore_mtl4fc_b_extendedrandtransformnew_fold2_complete\",\n",
    "    ),\n",
    "    \"lungCT_b_fold3\": os.path.join(\n",
    "        experiments,\n",
    "        \"test_nsclctumourpatchesnnunet_linear_zscore_mtl4fc_b_extendedrandtransformnew_fold3_complete\",\n",
    "    ),\n",
    "    \"lungCT_b_fold4\": os.path.join(\n",
    "        experiments,\n",
    "        \"test_nsclctumourpatchesnnunet_linear_zscore_mtl4fc_b_extendedrandtransformnew_fold4_complete\",\n",
    "    ),\n",
    "    \"lungCT_a\": os.path.join(\n",
    "        experiments,\n",
    "        \"test_nsclctumourpatchesnnunet_linear_zscore_mtl4fc_a_extendedrandtransformnewfulltraincv_complete\",\n",
    "    ),\n",
    "    \"lungCT_b\": os.path.join(\n",
    "        experiments,\n",
    "        \"test_nsclctumourpatchesnnunet_linear_zscore_mtl4fc_b_extendedrandtransformnewfulltraincv_complete\",\n",
    "    ),\n",
    "}\n",
    "\n",
    "\n",
    "log_names = {\n",
    "    \"CMNIST_a\": [\n",
    "        \"2022-10-27_13-05-44_120_bpred=1.0_bprog=1.0_finalact=None\",\n",
    "        \"2022-10-27_04-03-14_96_bpred=0.8_bprog=0.8_finalact=None\",\n",
    "    ],\n",
    "    \"CMNIST_b\": [\n",
    "        \"2022-10-26_21-51-30_120_bpred=1.0_bprog=1.0_finalact=None\",\n",
    "        \"2022-10-26_15-56-12_96_bpred=0.8_bprog=0.8_finalact=None\",\n",
    "    ],\n",
    "    \"CMNISTvline_a\": [\n",
    "        \"2022-11-02_11-35-26_120_bpred=1.0_bprog=1.0_finalact=None\",\n",
    "        \"2022-11-01_21-32-49_84_bpred=0.7_bprog=0.7_finalact=None\",\n",
    "        \"2022-11-01_12-13-19_60_bpred=0.5_bprog=0.5_finalact=None\",\n",
    "    ],\n",
    "    \"CMNISTvline_b\": [\n",
    "        \"2022-11-02_11-47-04_120_bpred=1.0_bprog=1.0_finalact=None\",\n",
    "        \"2022-11-01_21-42-48_84_bpred=0.7_bprog=0.7_finalact=None\",\n",
    "        \"2022-11-01_12-20-51_60_bpred=0.5_bprog=0.5_finalact=None\",\n",
    "    ],\n",
    "    \"cub_a\": [\n",
    "        \"2022-10-30_07-41-48_35_bpred=1.0_bprog=1.0_finalact=None\",\n",
    "        \"2022-10-29_21-04-59_28_bpred=0.8_bprog=0.8_finalact=None\",\n",
    "        \"2022-10-29_09-31-50_21_bpred=0.6_bprog=0.6_finalact=None\",\n",
    "    ],\n",
    "    \"cub_b\": [\n",
    "        \"2022-10-30_08-12-09_35_bpred=1.0_bprog=1.0_finalact=None\",\n",
    "        \"2022-10-29_21-35-28_28_bpred=0.8_bprog=0.8_finalact=None\",\n",
    "        \"2022-10-29_09-59-09_21_bpred=0.6_bprog=0.6_finalact=None\",\n",
    "    ],\n",
    "    \"isic_a\": [\n",
    "        \"2022-10-23_17-37-07_35_bpred=1.0_bprog=1.0_finalact=None\",\n",
    "        \"2022-10-23_03-42-00_28_bpred=0.8_bprog=0.8_finalact=None\",\n",
    "        \"2022-10-22_12-42-59_21_bpred=0.6_bprog=0.6_finalact=None\",\n",
    "    ],\n",
    "    \"isic_b\": [\n",
    "        \"2022-10-23_19-03-41_35_bpred=1.0_bprog=1.0_finalact=None\",\n",
    "        \"2022-10-23_05-53-30_28_bpred=0.8_bprog=0.8_finalact=None\",\n",
    "        \"2022-10-22_15-42-35_21_bpred=0.6_bprog=0.6_finalact=None\",\n",
    "    ],\n",
    "    \"isic_a_newarch\": [\n",
    "        \"2022-11-01_04-19-04_35_bpred=1.0_bprog=1.0_finalact=None\",\n",
    "        \"2022-10-31_12-00-21_28_bpred=0.8_bprog=0.8_finalact=None\",\n",
    "        \"2022-10-30_19-40-27_21_bpred=0.6_bprog=0.6_finalact=None\",\n",
    "    ],\n",
    "    \"isic_b_newarch\": [\n",
    "        \"2022-10-30_07-50-50_35_bpred=1.0_bprog=1.0_finalact=None\",\n",
    "        \"2022-10-30_01-22-52_28_bpred=0.8_bprog=0.8_finalact=None\",\n",
    "        \"2022-10-29_17-37-53_21_bpred=0.6_bprog=0.6_finalact=None\",\n",
    "    ],\n",
    "    \"lungCT_a_fold0\": [\n",
    "        \"2024-01-26_14-28-16_35_bpred=1.0_bprog=1.0_finalact=None_kfold_idx=0\",\n",
    "        \"2024-01-25_03-39-05_28_bpred=0.8_bprog=0.8_finalact=None_kfold_idx=0\",\n",
    "    ],\n",
    "    \"lungCT_a_fold1\": [\n",
    "        \"2024-01-29_19-17-43_0_bpred=1.0_bprog=1.0_finalact=None_kfold_idx=1\",\n",
    "        \"2024-01-30_19-53-21_4_bpred=0.8_bprog=0.8_finalact=None_kfold_idx=1\",\n",
    "    ],\n",
    "    \"lungCT_a_fold2\": [\n",
    "        \"2024-01-25_19-45-39_35_bpred=1.0_bprog=1.0_finalact=None_kfold_idx=2\",\n",
    "        \"2024-01-24_13-26-30_28_bpred=0.8_bprog=0.8_finalact=None_kfold_idx=2\",\n",
    "    ],  \n",
    "    \"lungCT_a_fold3\": [\n",
    "        \"2024-01-26_16-34-54_35_bpred=1.0_bprog=1.0_finalact=None_kfold_idx=3\",\n",
    "        \"2024-01-25_04-24-35_28_bpred=0.8_bprog=0.8_finalact=None_kfold_idx=3\",\n",
    "    ],  \n",
    "    \"lungCT_a_fold4\": [\n",
    "        \"2024-01-28_06-23-02_5_bpred=1.0_bprog=1.0_finalact=None_kfold_idx=4\",\n",
    "        \"2024-01-28_20-20-36_0_bpred=0.8_bprog=0.8_finalact=None_kfold_idx=4\",\n",
    "    ],\n",
    "    \"lungCT_b_fold0\": [\n",
    "        \"2024-01-25_19-48-28_35_bpred=1.0_bprog=1.0_finalact=None_kfold_idx=0\",\n",
    "        \"2024-01-24_13-29-39_28_bpred=0.8_bprog=0.8_finalact=None_kfold_idx=0\",\n",
    "    ],\n",
    "    \"lungCT_b_fold1\": [\n",
    "        \"2024-01-31_04-00-52_17_bpred=1.0_bprog=1.0_finalact=None_kfold_idx=1\",\n",
    "        \"2024-01-30_00-06-48_13_bpred=0.8_bprog=0.8_finalact=None_kfold_idx=1\",\n",
    "    ],\n",
    "    \"lungCT_b_fold2\": [\n",
    "        \"2024-01-29_14-41-45_0_bpred=1.0_bprog=1.0_finalact=None_kfold_idx=2\",\n",
    "        \"2024-01-30_14-13-38_4_bpred=0.8_bprog=0.8_finalact=None_kfold_idx=2\",\n",
    "    ],\n",
    "    \"lungCT_b_fold3\": [\n",
    "        \"2024-01-31_14-17-02_11_bpred=1.0_bprog=1.0_finalact=None_kfold_idx=3\",\n",
    "        \"2024-01-30_20-09-55_8_bpred=0.8_bprog=0.8_finalact=None_kfold_idx=3\",\n",
    "    ],  \n",
    "    \"lungCT_b_fold4\": [\n",
    "        \"2024-02-02_05-20-30_17_bpred=1.0_bprog=1.0_finalact=None_kfold_idx=4\",\n",
    "        \"2024-02-01_04-58-41_13_bpred=0.8_bprog=0.8_finalact=None_kfold_idx=4\",\n",
    "    ],  \n",
    "    \"lungCT_a\": [\n",
    "        \"2024-01-26_22-15-32_0_bpred=1.0_bprog=1.0_finalact=None_kfold_idx=None\",\n",
    "        \"2024-01-28_16-10-15_4_bpred=0.8_bprog=0.8_finalact=None_kfold_idx=None\",\n",
    "    ],\n",
    "    \"lungCT_b\": [\n",
    "        \"2024-01-26_21-54-06_0_bpred=1.0_bprog=1.0_finalact=None_kfold_idx=None\",\n",
    "        \"2024-01-29_01-23-41_4_bpred=0.8_bprog=0.8_finalact=None_kfold_idx=None\",\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e83064f0-61b7-44a6-bcfc-c63a491316e1",
   "metadata": {},
   "source": [
    "## Natural Image Datasets:\n",
    "### Coloured MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb60048-c9d4-4e03-9964-9000a68557e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"CMNIST_a\"\n",
    "data_name = \"CMNIST\"\n",
    "model_CMNIST_a, dl_CMNIST_a, bprog_CMNIST_a, bpred_CMNIST_a = (\n",
    "    get_interpretation(  # Two head\n",
    "        experiment_dir=experiment_dirs[name],\n",
    "        use_cuda=False,\n",
    "        n_batch=1000,\n",
    "        log_name=log_names[name][1],\n",
    "        get_saliency_maps=False,\n",
    "        dataset_root=dataset_root[data_name],\n",
    "        env=\"test\",\n",
    "    )\n",
    ")\n",
    "\n",
    "name = \"CMNIST_b\"\n",
    "data_name = \"CMNIST\"\n",
    "model_CMNIST_b, dl_CMNIST_b, bprog_CMNIST_b, bpred_CMNIST_b = (\n",
    "    get_interpretation(  # Cate\n",
    "        experiment_dir=experiment_dirs[name],\n",
    "        use_cuda=False,\n",
    "        n_batch=100,\n",
    "        log_name=log_names[name][1],\n",
    "        get_saliency_maps=False,\n",
    "        dataset_root=dataset_root[data_name],\n",
    "        env=\"test\",\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "data_CMNIST = next(iter(dl_CMNIST_a))\n",
    "data_CMNIST = data_CMNIST[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658d33b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 17  # 4, 12, 61, 10\n",
    "nt_type = \"smoothgrad\"\n",
    "nt_samples = 100\n",
    "nt_samples_batch_size = 10\n",
    "stdevs = 0.1\n",
    "\n",
    "# Exp. Gradients\n",
    "attr_eg_cmnist = []\n",
    "\n",
    "for model in (model_CMNIST_a, model_CMNIST_b):\n",
    "    model.cpu()\n",
    "    attr_method = GradientShap(TwoHead_Wrapper(model))\n",
    "    for target in (0, 1):\n",
    "        attr_values = attr_method.attribute(\n",
    "            data_CMNIST[n].unsqueeze(0),\n",
    "            n_samples=150,\n",
    "            stdevs=stdevs,\n",
    "            baselines=data_CMNIST,\n",
    "            target=target,\n",
    "        )\n",
    "        attr_eg_cmnist.append(attr_values.squeeze(0))\n",
    "\n",
    "for model in (model_CMNIST_a, model_CMNIST_b):\n",
    "    attr_method = GradientShap(CATE_Wrapper(model))\n",
    "    attr_values = attr_method.attribute(\n",
    "        data_CMNIST[n].unsqueeze(0),\n",
    "        n_samples=150,\n",
    "        stdevs=stdevs,\n",
    "        baselines=data_CMNIST,\n",
    "        target=0,\n",
    "    )\n",
    "    attr_eg_cmnist.append(attr_values.squeeze(0))\n",
    "\n",
    "attr_eg_cmnist = [attr_eg_cmnist[i] for i in [0, 1, 4, 2, 3, 5]]\n",
    "\n",
    "# Int. Gradients\n",
    "\n",
    "attr_ig_cmnist = []\n",
    "\n",
    "for model in (model_CMNIST_a, model_CMNIST_b):\n",
    "    attr_method = NoiseTunnel(IntegratedGradients(TwoHead_Wrapper(model)))\n",
    "    for target in (0, 1):\n",
    "        attr_values = attr_method.attribute(\n",
    "            data_CMNIST[n].unsqueeze(0),\n",
    "            target=target,\n",
    "            baselines=-0.4242 + 0.0001,\n",
    "            n_steps=50,\n",
    "            stdevs=stdevs,\n",
    "            nt_type=nt_type,\n",
    "            nt_samples=nt_samples,\n",
    "            nt_samples_batch_size=nt_samples_batch_size,\n",
    "        )\n",
    "        attr_ig_cmnist.append(attr_values.squeeze(0))\n",
    "\n",
    "for model in (model_CMNIST_a, model_CMNIST_b):\n",
    "    attr_method = NoiseTunnel(IntegratedGradients(CATE_Wrapper(model)))\n",
    "    attr_values = attr_method.attribute(\n",
    "        data_CMNIST[n].unsqueeze(0),\n",
    "        target=0,\n",
    "        baselines=-0.4242 + 0.0001,\n",
    "        n_steps=20,\n",
    "        stdevs=stdevs,\n",
    "        nt_type=nt_type,\n",
    "        nt_samples=nt_samples,\n",
    "        nt_samples_batch_size=nt_samples_batch_size,\n",
    "    )\n",
    "    attr_ig_cmnist.append(attr_values.squeeze(0))\n",
    "\n",
    "attr_ig_cmnist = [attr_ig_cmnist[i] for i in [0, 1, 4, 2, 3, 5]]\n",
    "\n",
    "# Guided GradCAM\n",
    "\n",
    "attr_gcam_cmnist = []\n",
    "\n",
    "for model in (model_CMNIST_a, model_CMNIST_b):\n",
    "    attr_method = GuidedGradCam(\n",
    "        TwoHead_Wrapper(model), TwoHead_Wrapper(model).model.model.layer1[0]\n",
    "    )\n",
    "    for target in (0, 1):\n",
    "        attr_values = attr_method.attribute(\n",
    "            data_CMNIST[n].unsqueeze(0),\n",
    "            target=target,\n",
    "        )\n",
    "        attr_gcam_cmnist.append(attr_values.squeeze(0))\n",
    "\n",
    "for model in (model_CMNIST_a, model_CMNIST_b):\n",
    "    attr_method = GuidedGradCam(\n",
    "        CATE_Wrapper(model), CATE_Wrapper(model).model.model.layer1[0]\n",
    "    )\n",
    "    attr_values = attr_method.attribute(\n",
    "        data_CMNIST[n].unsqueeze(0),\n",
    "        target=0,\n",
    "    )\n",
    "    attr_gcam_cmnist.append(attr_values.squeeze(0))\n",
    "\n",
    "attr_gcam_cmnist = [attr_gcam_cmnist[i] for i in [0, 1, 4, 2, 3, 5]]\n",
    "\n",
    "# Guided Backprob\n",
    "\n",
    "attr_gbp_cmnist = []\n",
    "\n",
    "for model in (model_CMNIST_a, model_CMNIST_b):\n",
    "    attr_method = GuidedBackprop(TwoHead_Wrapper(model))\n",
    "    for target in (0, 1):\n",
    "        attr_values = attr_method.attribute(\n",
    "            data_CMNIST[n].unsqueeze(0),\n",
    "            target=target,\n",
    "        )\n",
    "        attr_gbp_cmnist.append(attr_values.squeeze(0))\n",
    "\n",
    "for model in (model_CMNIST_a, model_CMNIST_b):\n",
    "    attr_method = GuidedBackprop(CATE_Wrapper(model))\n",
    "    attr_values = attr_method.attribute(\n",
    "        data_CMNIST[n].unsqueeze(0),\n",
    "        target=0,\n",
    "    )\n",
    "    attr_gbp_cmnist.append(attr_values.squeeze(0))\n",
    "\n",
    "attr_gbp_cmnist = [attr_gbp_cmnist[i] for i in [0, 1, 4, 2, 3, 5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87b89ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.transpose(data_CMNIST[n].cpu().detach().numpy(), (1, 2, 0))\n",
    "img = (img - img.min()) / (img.max() - img.min())\n",
    "channel = [\"red\", \"green\", \"blue\"]\n",
    "attr_type = [\"EG\", \"IG\", \"GGCAM\", \"GBP\"]\n",
    "model_type = [\n",
    "    \"TwoHead_0_a\",\n",
    "    \"TwoHead_1_a\",\n",
    "    \"CATE_a\",\n",
    "    \"TwoHead_0_b\",\n",
    "    \"TwoHead_1_b\",\n",
    "    \"CATE_b\",\n",
    "]\n",
    "\n",
    "if not os.path.exists(\"./Images/cmnist/\" + str(n) + \"/\"):\n",
    "    os.makedirs(\"./Images/cmnist/\" + str(n) + \"/\")\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt._original_dpi = 200\n",
    "\n",
    "plt.savefig(\n",
    "    \"./Images/cmnist/\" + str(n) + \"/original.png\", bbox_inches=\"tight\", pad_inches=0\n",
    ")\n",
    "plt.close()\n",
    "\n",
    "\n",
    "for idx, attr in enumerate(\n",
    "    [attr_eg_cmnist, attr_ig_cmnist, attr_gcam_cmnist, attr_gbp_cmnist]\n",
    "):\n",
    "    for model in range(6):\n",
    "        for rgb in range(3):\n",
    "            fig, axis = vis.visualize_image_attr_multiple(\n",
    "                attr[model][rgb].unsqueeze(-1).cpu().detach().numpy(),\n",
    "                img,\n",
    "                [\"heat_map\"],\n",
    "                [\"all\"],\n",
    "                cmap=heat_cmap,\n",
    "                show_colorbar=False,\n",
    "                use_pyplot=False,\n",
    "            )\n",
    "\n",
    "            managed_fig = plt.figure()\n",
    "            canvas_manager = managed_fig.canvas.manager\n",
    "            canvas_manager.canvas.figure = fig\n",
    "            fig.set_canvas(canvas_manager.canvas)\n",
    "            fig._original_dpi = 200\n",
    "\n",
    "            plt.savefig(\n",
    "                \"./Images/cmnist/\"\n",
    "                + str(n)\n",
    "                + \"/\"\n",
    "                + str(attr_type[idx])\n",
    "                + \"_\"\n",
    "                + model_type[model]\n",
    "                + \"_\"\n",
    "                + channel[rgb]\n",
    "                + \".png\",\n",
    "                bbox_inches=\"tight\",\n",
    "                pad_inches=0,\n",
    "            )\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1e91f0",
   "metadata": {},
   "source": [
    "### CUB 2011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cbbbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"cub_a\"\n",
    "data_name = \"cub\"\n",
    "model_cub_a, dl_cub_a, bprog_cub_a, bpred_cub_a = get_interpretation(\n",
    "    experiment_dir=experiment_dirs[name],\n",
    "    use_cuda=True,\n",
    "    n_batch=1100,\n",
    "    log_name=log_names[name][0],\n",
    "    get_saliency_maps=False,\n",
    "    dataset_root=dataset_root[data_name],\n",
    "    env=\"val\",\n",
    ")\n",
    "\n",
    "name = \"cub_b\"\n",
    "data_name = \"cub\"\n",
    "model_cub_b, dl_cub_b, bprog_cub_b, bpred_cub_b = get_interpretation(\n",
    "    experiment_dir=experiment_dirs[name],\n",
    "    use_cuda=True,\n",
    "    n_batch=100,\n",
    "    log_name=log_names[name][0],\n",
    "    get_saliency_maps=False,\n",
    "    dataset_root=dataset_root[data_name],\n",
    "    env=\"val\",\n",
    ")\n",
    "\n",
    "data_cub = next(iter(dl_cub_a))\n",
    "label_cub = data_cub[1]\n",
    "data_cub = data_cub[0].to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab8e8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 775  # 335 #1015 #8 22\n",
    "nt_type = \"smoothgrad\"\n",
    "nt_samples = 50\n",
    "nt_samples_batch_size = 5\n",
    "\n",
    "\n",
    "# Exp. Gradients\n",
    "attr_eg_cub = []\n",
    "\n",
    "for model in (model_cub_a, model_cub_b):\n",
    "    attr_method = GradientShap(TwoHead_Wrapper(model))\n",
    "    for target in (0, 1):\n",
    "\n",
    "        attr_values = attr_method.attribute(\n",
    "            data_cub[n].unsqueeze(0),\n",
    "            n_samples=300,\n",
    "            # stdevs=0.001,\n",
    "            baselines=data_cub,\n",
    "            target=target,\n",
    "            stdevs=0.2,\n",
    "        )\n",
    "        attr_eg_cub.append(attr_values.squeeze(0))\n",
    "\n",
    "for model in (model_cub_a, model_cub_b):\n",
    "    attr_method = GradientShap(CATE_Wrapper(model))\n",
    "    attr_values = attr_method.attribute(\n",
    "        data_cub[n].unsqueeze(0),\n",
    "        n_samples=300,\n",
    "        # stdevs=0.001,\n",
    "        baselines=data_cub,\n",
    "        target=0,\n",
    "        stdevs=0.2,\n",
    "    )\n",
    "    attr_eg_cub.append(attr_values.squeeze(0))\n",
    "\n",
    "attr_eg_cub = [attr_eg_cub[i] for i in [0, 1, 4, 2, 3, 5]]\n",
    "\n",
    "# Int. Gradients\n",
    "\n",
    "attr_ig_cub = []\n",
    "\n",
    "for model in (model_cub_a, model_cub_b):\n",
    "    attr_method = NoiseTunnel(IntegratedGradients(TwoHead_Wrapper(model)))\n",
    "    for target in (0, 1):\n",
    "        attr_values = attr_method.attribute(\n",
    "            data_cub[n].unsqueeze(0),\n",
    "            target=target,\n",
    "            baselines=(torch.ones_like(data_cub[n]) * 0).unsqueeze(0),\n",
    "            stdevs=0.2,\n",
    "            nt_type=nt_type,\n",
    "            nt_samples=nt_samples,\n",
    "            nt_samples_batch_size=nt_samples_batch_size,\n",
    "        )\n",
    "        attr_ig_cub.append(attr_values.squeeze(0))\n",
    "\n",
    "for model in (model_cub_a, model_cub_b):\n",
    "    attr_method = NoiseTunnel(IntegratedGradients(CATE_Wrapper(model)))\n",
    "    attr_values = attr_method.attribute(\n",
    "        data_cub[n].unsqueeze(0),\n",
    "        target=0,\n",
    "        baselines=(torch.ones_like(data_cub[n]) * 0).unsqueeze(0),\n",
    "        stdevs=0.2,\n",
    "        nt_type=nt_type,\n",
    "        nt_samples=nt_samples,\n",
    "        nt_samples_batch_size=nt_samples_batch_size,\n",
    "    )\n",
    "    attr_ig_cub.append(attr_values.squeeze(0))\n",
    "\n",
    "attr_ig_cub = [attr_ig_cub[i] for i in [0, 1, 4, 2, 3, 5]]\n",
    "\n",
    "# GradCAM\n",
    "\n",
    "attr_gcam_cub = []\n",
    "for model in (model_cub_a, model_cub_b):\n",
    "    attr_method = GradCAM(\n",
    "        model=TwoHead_Wrapper(model),\n",
    "        target_layers=[TwoHead_Wrapper(model).model.model.layer4[-1]],\n",
    "    )\n",
    "    for target in (0, 1):\n",
    "        attr_values = attr_method(\n",
    "            input_tensor=data_cub[n].unsqueeze(0),\n",
    "            targets=[ClassifierOutputTarget(target)],\n",
    "        )\n",
    "        attr_gcam_cub.append(attr_values.squeeze(0))\n",
    "\n",
    "for model in (model_cub_a, model_cub_b):\n",
    "    attr_method = GradCAM(\n",
    "        model=CATE_Wrapper(model),\n",
    "        target_layers=[CATE_Wrapper(model).model.model.layer4[-1]],\n",
    "    )\n",
    "    attr_values = attr_method(\n",
    "        input_tensor=data_cub[n].unsqueeze(0), targets=[RawScoresOutputTarget()]\n",
    "    )\n",
    "    attr_gcam_cub.append(attr_values.squeeze(0))\n",
    "\n",
    "attr_gcam_cub = [attr_gcam_cub[i] for i in [0, 1, 4, 2, 3, 5]]\n",
    "\n",
    "# Guided Backprob\n",
    "\n",
    "attr_gbp_cub = []\n",
    "for model in (model_cub_a, model_cub_b):\n",
    "    attr_method = NoiseTunnel(GuidedBackprop(TwoHead_Wrapper(model)))\n",
    "    for target in (0, 1):\n",
    "        attr_values = attr_method.attribute(\n",
    "            data_cub[n].unsqueeze(0),\n",
    "            target=target,\n",
    "            stdevs=0.2,\n",
    "            nt_type=nt_type,\n",
    "            nt_samples=nt_samples,\n",
    "            nt_samples_batch_size=nt_samples_batch_size,\n",
    "        )\n",
    "        attr_gbp_cub.append(attr_values.squeeze(0))\n",
    "\n",
    "for model in (model_cub_a, model_cub_b):\n",
    "    attr_method = NoiseTunnel(GuidedBackprop(CATE_Wrapper(model)))\n",
    "    attr_values = attr_method.attribute(\n",
    "        data_cub[n].unsqueeze(0),\n",
    "        target=0,\n",
    "        stdevs=0.2,\n",
    "        nt_type=nt_type,\n",
    "        nt_samples=nt_samples,\n",
    "        nt_samples_batch_size=nt_samples_batch_size,\n",
    "    )\n",
    "    attr_gbp_cub.append(attr_values.squeeze(0))\n",
    "\n",
    "attr_gbp_cub = [attr_gbp_cub[i] for i in [0, 1, 4, 2, 3, 5]]\n",
    "\n",
    "\n",
    "# Guided GradCAM\n",
    "attr_ggcam_cub = []\n",
    "\n",
    "for model in (model_cub_a, model_cub_b):\n",
    "    attr_method = NoiseTunnel(\n",
    "        GuidedGradCam(TwoHead_Wrapper(model), TwoHead_Wrapper(model).model.model.conv)\n",
    "    )\n",
    "    for target in (0, 1):\n",
    "        attr_values = attr_method.attribute(\n",
    "            data_cub[n].unsqueeze(0),\n",
    "            target=target,\n",
    "            stdevs=0.2,\n",
    "            nt_type=nt_type,\n",
    "            nt_samples=nt_samples,\n",
    "            nt_samples_batch_size=nt_samples_batch_size,\n",
    "        )\n",
    "\n",
    "        attr_ggcam_cub.append(attr_values.squeeze(0))\n",
    "\n",
    "for model in (model_cub_a, model_cub_b):\n",
    "    attr_method = NoiseTunnel(\n",
    "        GuidedGradCam(CATE_Wrapper(model), CATE_Wrapper(model).model.model.conv)\n",
    "    )\n",
    "    attr_values = attr_method.attribute(\n",
    "        data_cub[n].unsqueeze(0),\n",
    "        target=0,\n",
    "        stdevs=0.2,\n",
    "        nt_type=nt_type,\n",
    "        nt_samples=nt_samples,\n",
    "        nt_samples_batch_size=nt_samples_batch_size,\n",
    "    )\n",
    "    attr_ggcam_cub.append(attr_values.squeeze(0))\n",
    "\n",
    "attr_ggcam_cub = [attr_ggcam_cub[i] for i in [0, 1, 4, 2, 3, 5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e4adee",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.transpose(data_cub[n].cpu().detach().numpy(), (1, 2, 0))\n",
    "img = (img - img.min()) / (img.max() - img.min())\n",
    "attr_type = [\"EG\", \"IG\", \"GCAM\", \"GBP\", \"GGCAM\"]\n",
    "model_type = [\n",
    "    \"TwoHead_0_a\",\n",
    "    \"TwoHead_1_a\",\n",
    "    \"CATE_a\",\n",
    "    \"TwoHead_0_b\",\n",
    "    \"TwoHead_1_b\",\n",
    "    \"CATE_b\",\n",
    "]\n",
    "\n",
    "if not os.path.exists(\"./Images/cub2011/\" + str(n) + \"/\"):\n",
    "    os.makedirs(\"./Images/cub2011/\" + str(n) + \"/\")\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt._original_dpi = 200\n",
    "\n",
    "plt.savefig(\n",
    "    \"./Images/cub2011/\" + str(n) + \"/original.png\", bbox_inches=\"tight\", pad_inches=0\n",
    ")\n",
    "plt.close()\n",
    "\n",
    "norm = [0.0005, 0.0005, None, 0.0005, 0.0]\n",
    "\n",
    "for idx, attr in enumerate(\n",
    "    [attr_eg_cub, attr_ig_cub, attr_gcam_cub, attr_gbp_cub, attr_ggcam_cub]\n",
    "):\n",
    "    for model in range(6):\n",
    "        if idx == 2:\n",
    "            gcam_vis = show_cam_on_image(img, attr[model], use_rgb=True)\n",
    "            plt.imshow(gcam_vis)\n",
    "            plt.axis(\"off\")\n",
    "            plt.tight_layout()\n",
    "            plt._original_dpi = 200\n",
    "\n",
    "            plt.savefig(\n",
    "                \"./Images/cub2011/\"\n",
    "                + str(n)\n",
    "                + \"/\"\n",
    "                + str(attr_type[idx])\n",
    "                + \"_\"\n",
    "                + model_type[model]\n",
    "                + \".png\",\n",
    "                bbox_inches=\"tight\",\n",
    "                pad_inches=0,\n",
    "            )\n",
    "            plt.close()\n",
    "        else:\n",
    "            fig, axis = vis.visualize_image_attr_multiple(\n",
    "                np.where(\n",
    "                    np.transpose(np.abs(attr[model].cpu().detach().numpy()), (1, 2, 0))\n",
    "                    < norm[idx],\n",
    "                    0,\n",
    "                    np.transpose(attr[model].cpu().detach().numpy(), (1, 2, 0)),\n",
    "                ),\n",
    "                img,\n",
    "                [\"heat_map\"],\n",
    "                [\"all\"],\n",
    "                cmap=heat_cmap,\n",
    "                show_colorbar=False,\n",
    "                use_pyplot=False,\n",
    "            )\n",
    "\n",
    "            managed_fig = plt.figure()\n",
    "            canvas_manager = managed_fig.canvas.manager\n",
    "            canvas_manager.canvas.figure = fig\n",
    "            fig.set_canvas(canvas_manager.canvas)\n",
    "            fig._original_dpi = 200\n",
    "\n",
    "            plt.savefig(\n",
    "                \"./Images/cub2011/\"\n",
    "                + str(n)\n",
    "                + \"/\"\n",
    "                + str(attr_type[idx])\n",
    "                + \"_\"\n",
    "                + model_type[model]\n",
    "                + \".png\",\n",
    "                bbox_inches=\"tight\",\n",
    "                pad_inches=0,\n",
    "            )\n",
    "            plt.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "71d1cdee",
   "metadata": {},
   "source": [
    "## Medical Image Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "01f9f638",
   "metadata": {},
   "source": [
    "### ISIC 2018 Skin Lesions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e080967",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"isic_a\"\n",
    "# name = \"isic_a_newarch\"\n",
    "data_name = \"isic\"\n",
    "model_isic_a, dl_isic_a, bprog_isic_a, bpred_isic_a = get_interpretation(\n",
    "    experiment_dir=experiment_dirs[name],\n",
    "    use_cuda=False,\n",
    "    n_batch=300,\n",
    "    log_name=log_names[name][1],\n",
    "    get_saliency_maps=False,\n",
    "    dataset_root=dataset_root[data_name],\n",
    "    env=\"val\",\n",
    ")  # use validation data for preliminary experiments\n",
    "\n",
    "name = \"isic_b\"\n",
    "# name = \"isic_b_newarch\"\n",
    "data_name = \"isic\"\n",
    "model_isic_b, dl_isic_b, bprog_isic_b, bpred_isic_b = get_interpretation(\n",
    "    experiment_dir=experiment_dirs[name],\n",
    "    use_cuda=False,\n",
    "    n_batch=150,\n",
    "    log_name=log_names[name][1],\n",
    "    get_saliency_maps=False,\n",
    "    dataset_root=dataset_root[data_name],\n",
    "    env=\"val\",\n",
    ")  # use validation data for preliminary experiments\n",
    "\n",
    "\n",
    "data_isic = next(iter(dl_isic_a))\n",
    "label_isic = data_isic[1]\n",
    "data_isic = data_isic[0].to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e084ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 13  # 77 39  76  101 80\n",
    "nt_type = \"smoothgrad\"\n",
    "nt_samples = 50\n",
    "nt_samples_batch_size = 5\n",
    "\n",
    "\n",
    "# Exp. Gradients\n",
    "attr_eg_isic = []\n",
    "\n",
    "for model in (model_isic_a, model_isic_b):\n",
    "    attr_method = GradientShap(TwoHead_Wrapper(model))\n",
    "    for target in (0, 1):\n",
    "\n",
    "        attr_values = attr_method.attribute(\n",
    "            data_isic[n].unsqueeze(0),\n",
    "            n_samples=300,\n",
    "            # stdevs=0.001,\n",
    "            baselines=data_isic,\n",
    "            target=target,\n",
    "            stdevs=0.0001,\n",
    "        )\n",
    "        attr_eg_isic.append(attr_values.squeeze(0))\n",
    "\n",
    "for model in (model_isic_a, model_isic_b):\n",
    "    attr_method = GradientShap(CATE_Wrapper(model))\n",
    "    attr_values = attr_method.attribute(\n",
    "        data_isic[n].unsqueeze(0),\n",
    "        n_samples=300,\n",
    "        # stdevs=0.001,\n",
    "        baselines=data_isic,\n",
    "        target=0,\n",
    "        stdevs=0.0001,\n",
    "    )\n",
    "    attr_eg_isic.append(attr_values.squeeze(0))\n",
    "\n",
    "attr_eg_isic = [attr_eg_isic[i] for i in [0, 1, 4, 2, 3, 5]]\n",
    "\n",
    "# Int. Gradients\n",
    "\n",
    "attr_ig_isic = []\n",
    "\n",
    "for model in (model_isic_a, model_isic_b):\n",
    "    attr_method = NoiseTunnel(IntegratedGradients(TwoHead_Wrapper(model)))\n",
    "    for target in (0, 1):\n",
    "        attr_values = attr_method.attribute(\n",
    "            data_isic[n].unsqueeze(0),\n",
    "            target=target,\n",
    "            baselines=(torch.ones_like(data_isic[n]) * 0).unsqueeze(0),\n",
    "            stdevs=0.2,\n",
    "            nt_type=nt_type,\n",
    "            nt_samples=nt_samples,\n",
    "            nt_samples_batch_size=nt_samples_batch_size,\n",
    "        )\n",
    "        attr_ig_isic.append(attr_values.squeeze(0))\n",
    "\n",
    "for model in (model_isic_a, model_isic_b):\n",
    "    attr_method = NoiseTunnel(IntegratedGradients(CATE_Wrapper(model)))\n",
    "    attr_values = attr_method.attribute(\n",
    "        data_isic[n].unsqueeze(0),\n",
    "        target=0,\n",
    "        baselines=(torch.ones_like(data_isic[n]) * 0).unsqueeze(0),\n",
    "        stdevs=0.2,\n",
    "        nt_type=nt_type,\n",
    "        nt_samples=nt_samples,\n",
    "        nt_samples_batch_size=nt_samples_batch_size,\n",
    "    )\n",
    "    attr_ig_isic.append(attr_values.squeeze(0))\n",
    "\n",
    "attr_ig_isic = [attr_ig_isic[i] for i in [0, 1, 4, 2, 3, 5]]\n",
    "\n",
    "# GradCAM\n",
    "\n",
    "attr_gcam_isic = []\n",
    "for model in (model_isic_a, model_isic_b):\n",
    "    attr_method = GradCAM(\n",
    "        model=TwoHead_Wrapper(model),\n",
    "        target_layers=[TwoHead_Wrapper(model).model.model.layer4[-1]],\n",
    "    )\n",
    "    for target in (0, 1):\n",
    "        attr_values = attr_method(\n",
    "            input_tensor=data_isic[n].unsqueeze(0),\n",
    "            targets=[ClassifierOutputTarget(target)],\n",
    "        )\n",
    "        attr_gcam_isic.append(attr_values.squeeze(0))\n",
    "\n",
    "for model in (model_isic_a, model_isic_b):\n",
    "    attr_method = GradCAM(\n",
    "        model=CATE_Wrapper(model),\n",
    "        target_layers=[CATE_Wrapper(model).model.model.layer4[-1]],\n",
    "    )\n",
    "    attr_values = attr_method(\n",
    "        input_tensor=data_isic[n].unsqueeze(0), targets=[RawScoresOutputTarget()]\n",
    "    )\n",
    "    attr_gcam_isic.append(attr_values.squeeze(0))\n",
    "\n",
    "attr_gcam_isic = [attr_gcam_isic[i] for i in [0, 1, 4, 2, 3, 5]]\n",
    "\n",
    "# Guided Backprob\n",
    "attr_gbp_isic = []\n",
    "for model in (model_isic_a, model_isic_b):\n",
    "    attr_method = NoiseTunnel(GuidedBackprop(TwoHead_Wrapper(model)))\n",
    "    for target in (0, 1):\n",
    "        attr_values = attr_method.attribute(\n",
    "            data_isic[n].unsqueeze(0),\n",
    "            target=target,\n",
    "            stdevs=0.2,\n",
    "            nt_type=nt_type,\n",
    "            nt_samples=nt_samples,\n",
    "            nt_samples_batch_size=nt_samples_batch_size,\n",
    "        )\n",
    "        attr_gbp_isic.append(attr_values.squeeze(0))\n",
    "\n",
    "for model in (model_isic_a, model_isic_b):\n",
    "    attr_method = NoiseTunnel(GuidedBackprop(CATE_Wrapper(model)))\n",
    "    attr_values = attr_method.attribute(\n",
    "        data_isic[n].unsqueeze(0),\n",
    "        target=0,\n",
    "        stdevs=0.2,\n",
    "        nt_type=nt_type,\n",
    "        nt_samples=nt_samples,\n",
    "        nt_samples_batch_size=nt_samples_batch_size,\n",
    "    )\n",
    "    attr_gbp_isic.append(attr_values.squeeze(0))\n",
    "\n",
    "attr_gbp_isic = [attr_gbp_isic[i] for i in [0, 1, 4, 2, 3, 5]]\n",
    "\n",
    "\n",
    "# Guided GradCAM\n",
    "attr_ggcam_isic = []\n",
    "\n",
    "for model in (model_isic_a, model_isic_b):\n",
    "    attr_method = NoiseTunnel(\n",
    "        GuidedGradCam(TwoHead_Wrapper(model), TwoHead_Wrapper(model).model.model.conv)\n",
    "    )\n",
    "    for target in (0, 1):\n",
    "        attr_values = attr_method.attribute(\n",
    "            data_isic[n].unsqueeze(0),\n",
    "            target=target,\n",
    "            stdevs=0.0001,\n",
    "            nt_type=nt_type,\n",
    "            nt_samples=nt_samples,\n",
    "            nt_samples_batch_size=nt_samples_batch_size,\n",
    "        )\n",
    "\n",
    "        attr_ggcam_isic.append(attr_values.squeeze(0))\n",
    "\n",
    "for model in (model_isic_a, model_isic_b):\n",
    "    attr_method = NoiseTunnel(\n",
    "        GuidedGradCam(CATE_Wrapper(model), CATE_Wrapper(model).model.model.conv)\n",
    "    )\n",
    "    attr_values = attr_method.attribute(\n",
    "        data_isic[n].unsqueeze(0),\n",
    "        target=0,\n",
    "        stdevs=0.0001,\n",
    "        nt_type=nt_type,\n",
    "        nt_samples=nt_samples,\n",
    "        nt_samples_batch_size=nt_samples_batch_size,\n",
    "    )\n",
    "    attr_ggcam_isic.append(attr_values.squeeze(0))\n",
    "\n",
    "attr_ggcam_isic = [attr_ggcam_isic[i] for i in [0, 1, 4, 2, 3, 5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b07f787",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.transpose(data_isic[n].cpu().detach().numpy(), (1, 2, 0))\n",
    "img = (img - img.min()) / (img.max() - img.min())\n",
    "attr_type = [\"EG\", \"IG\", \"GCAM\", \"GBP\", \"GGCAM\"]\n",
    "model_type = [\n",
    "    \"TwoHead_0_a\",\n",
    "    \"TwoHead_1_a\",\n",
    "    \"CATE_a\",\n",
    "    \"TwoHead_0_b\",\n",
    "    \"TwoHead_1_b\",\n",
    "    \"CATE_b\",\n",
    "]\n",
    "\n",
    "if not os.path.exists(\"./Images/isic/\" + str(n) + \"/\"):\n",
    "    os.makedirs(\"./Images/isic/\" + str(n) + \"/\")\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt._original_dpi = 200\n",
    "\n",
    "plt.savefig(\n",
    "    \"./Images/isic/\" + str(n) + \"/original.png\", bbox_inches=\"tight\", pad_inches=0\n",
    ")\n",
    "plt.close()\n",
    "\n",
    "norm = [0.0007, 0.0007, None, 0.0007, 0.0]\n",
    "\n",
    "for idx, attr in enumerate(\n",
    "    [attr_eg_isic, attr_ig_isic, attr_gcam_isic, attr_gbp_isic, attr_ggcam_isic]\n",
    "):\n",
    "    for model in range(6):\n",
    "        if idx == 2:\n",
    "            gcam_vis = show_cam_on_image(img, attr[model], use_rgb=True)\n",
    "            plt.imshow(gcam_vis)\n",
    "            plt.axis(\"off\")\n",
    "            plt.tight_layout()\n",
    "            plt._original_dpi = 200\n",
    "\n",
    "            plt.savefig(\n",
    "                \"./Images/isic/\"\n",
    "                + str(n)\n",
    "                + \"/\"\n",
    "                + str(attr_type[idx])\n",
    "                + \"_\"\n",
    "                + model_type[model]\n",
    "                + \".png\",\n",
    "                bbox_inches=\"tight\",\n",
    "                pad_inches=0,\n",
    "            )\n",
    "            plt.close()\n",
    "        else:\n",
    "            fig, axis = vis.visualize_image_attr_multiple(\n",
    "                np.where(\n",
    "                    np.transpose(np.abs(attr[model].cpu().detach().numpy()), (1, 2, 0))\n",
    "                    < norm[idx],\n",
    "                    0,\n",
    "                    np.transpose(attr[model].cpu().detach().numpy(), (1, 2, 0)),\n",
    "                ),\n",
    "                img,\n",
    "                [\"heat_map\"],\n",
    "                [\"all\"],\n",
    "                cmap=heat_cmap,\n",
    "                show_colorbar=False,\n",
    "                use_pyplot=False,\n",
    "            )\n",
    "\n",
    "            managed_fig = plt.figure()\n",
    "            canvas_manager = managed_fig.canvas.manager\n",
    "            canvas_manager.canvas.figure = fig\n",
    "            fig.set_canvas(canvas_manager.canvas)\n",
    "            fig._original_dpi = 200\n",
    "\n",
    "            plt.savefig(\n",
    "                \"./Images/isic/\"\n",
    "                + str(n)\n",
    "                + \"/\"\n",
    "                + str(attr_type[idx])\n",
    "                + \"_\"\n",
    "                + model_type[model]\n",
    "                + \".png\",\n",
    "                bbox_inches=\"tight\",\n",
    "                pad_inches=0,\n",
    "            )\n",
    "            plt.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2de74a1c",
   "metadata": {},
   "source": [
    "### Lung CT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82727e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"lungCT_a\"\n",
    "data_name = \"lungCT\"\n",
    "model_lungCT_a, dl_lungCT_a, bprog_lungCT_a, bpred_lungCT_a, dl_lungCT_seg_a = (\n",
    "    get_interpretation(\n",
    "        experiment_dir=experiment_dirs[name],\n",
    "        use_cuda=False,\n",
    "        n_batch=83,\n",
    "        log_name=log_names[name][1],\n",
    "        get_saliency_maps=False,\n",
    "        dataset_root=dataset_root[data_name],\n",
    "        env=\"test\",\n",
    "        get_segmentation_dl=True,\n",
    "        checkpoint_num=-1,\n",
    "    )\n",
    ")\n",
    "\n",
    "name = \"lungCT_b\"\n",
    "data_name = \"lungCT\"\n",
    "model_lungCT_b, dl_lungCT_b, bprog_lungCT_b, bpred_lungCT_b = get_interpretation(\n",
    "    experiment_dir=experiment_dirs[name],\n",
    "    use_cuda=False,\n",
    "    n_batch=20,\n",
    "    log_name=log_names[name][1],\n",
    "    get_saliency_maps=False,\n",
    "    dataset_root=dataset_root[data_name],\n",
    "    env=\"test\",\n",
    "    checkpoint_num=-1,\n",
    ")\n",
    "\n",
    "\n",
    "seg_lungCT = next(iter(dl_lungCT_seg_a)).numpy()\n",
    "data_lungCT = next(iter(dl_lungCT_a))\n",
    "data_lungCT = torch.Tensor(data_lungCT[0]).to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fc9fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 8\n",
    "nt_type = \"smoothgrad\"\n",
    "nt_samples = 10\n",
    "nt_samples_batch_size = 2\n",
    "stdevs = 80.0\n",
    "\n",
    "# Exp. Gradients\n",
    "attr_eg_lungCT = []\n",
    "\n",
    "for model in (model_lungCT_a, model_lungCT_b):\n",
    "    attr_method = GradientShap(TwoHead_Wrapper(model))\n",
    "    for target in (0, 1):\n",
    "\n",
    "        attr_values = attr_method.attribute(\n",
    "            data_lungCT[n].unsqueeze(0),\n",
    "            n_samples=50,\n",
    "            # stdevs=0.001,\n",
    "            baselines=data_lungCT,\n",
    "            target=target,\n",
    "            stdevs=stdevs,\n",
    "        )\n",
    "        attr_eg_lungCT.append(normalize_pos_neg(attr_values.squeeze(0)))\n",
    "\n",
    "for model in (model_lungCT_a, model_lungCT_b):\n",
    "    attr_method = GradientShap(CATE_Wrapper(model))\n",
    "    attr_values = attr_method.attribute(\n",
    "        data_lungCT[n].unsqueeze(0),\n",
    "        n_samples=50,\n",
    "        # stdevs=0.001,\n",
    "        baselines=data_lungCT,\n",
    "        target=0,\n",
    "        stdevs=stdevs,\n",
    "    )\n",
    "    attr_eg_lungCT.append(normalize_pos_neg(attr_values.squeeze(0)))\n",
    "\n",
    "attr_eg_lungCT = [attr_eg_lungCT[i] for i in [0, 1, 4, 2, 3, 5]]\n",
    "\n",
    "# Int. Gradients\n",
    "\n",
    "attr_ig_lungCT = []\n",
    "from captum.attr import Saliency\n",
    "\n",
    "for model in (model_lungCT_a, model_lungCT_b):\n",
    "    attr_method = NoiseTunnel(IntegratedGradients(TwoHead_Wrapper(model)))\n",
    "    for target in (0, 1):\n",
    "        attr_values = attr_method.attribute(\n",
    "            data_lungCT[n].unsqueeze(0),\n",
    "            target=target,\n",
    "            baselines=-1150,\n",
    "            n_steps=20,\n",
    "            stdevs=stdevs,\n",
    "            nt_type=nt_type,\n",
    "            nt_samples=nt_samples,\n",
    "            nt_samples_batch_size=nt_samples_batch_size,\n",
    "        )\n",
    "        attr_ig_lungCT.append(normalize_pos_neg(attr_values.squeeze(0)))\n",
    "\n",
    "for model in (model_lungCT_a, model_lungCT_b):\n",
    "    attr_method = NoiseTunnel(IntegratedGradients(CATE_Wrapper(model)))\n",
    "    attr_values = attr_method.attribute(\n",
    "        data_lungCT[n].unsqueeze(0),\n",
    "        target=0,\n",
    "        baselines=-1150,\n",
    "        n_steps=20,\n",
    "        stdevs=stdevs,\n",
    "        nt_type=nt_type,\n",
    "        nt_samples=nt_samples,\n",
    "        nt_samples_batch_size=nt_samples_batch_size,\n",
    "    )\n",
    "    attr_ig_lungCT.append(normalize_pos_neg(attr_values.squeeze(0)))\n",
    "\n",
    "attr_ig_lungCT = [attr_ig_lungCT[i] for i in [0, 1, 4, 2, 3, 5]]\n",
    "\n",
    "# GradCAM\n",
    "\n",
    "attr_gcam_lungCT = []\n",
    "for model in (model_lungCT_a, model_lungCT_b):\n",
    "    attr_method = GradCAM3D(\n",
    "        model=TwoHead_Wrapper(model),\n",
    "        target_layers=[\n",
    "            TwoHead_Wrapper(model).model.model.layer1,\n",
    "            TwoHead_Wrapper(model).model.model.layer2,\n",
    "            TwoHead_Wrapper(model).model.model.layer3,\n",
    "        ],\n",
    "    )\n",
    "    for target in (0, 1):\n",
    "        attr_values = attr_method(\n",
    "            input_tensor=data_lungCT[n].unsqueeze(0),\n",
    "            targets=[ClassifierOutputTarget(target)],\n",
    "        )\n",
    "        attr_gcam_lungCT.append(normalize_pos_zero(attr_values.squeeze(0)))\n",
    "\n",
    "for model in (model_lungCT_a, model_lungCT_b):\n",
    "    attr_method = GradCAM3D(\n",
    "        model=CATE_Wrapper(model),\n",
    "        target_layers=[\n",
    "            CATE_Wrapper(model).model.model.layer1,\n",
    "            CATE_Wrapper(model).model.model.layer2,\n",
    "            CATE_Wrapper(model).model.model.layer3,\n",
    "        ],\n",
    "    )\n",
    "    attr_values = attr_method(\n",
    "        input_tensor=data_lungCT[n].unsqueeze(0), targets=[RawScoresOutputTarget()]\n",
    "    )\n",
    "    attr_gcam_lungCT.append(normalize_pos_zero(attr_values.squeeze(0)))\n",
    "\n",
    "attr_gcam_lungCT = [attr_gcam_lungCT[i] for i in [0, 1, 4, 2, 3, 5]]\n",
    "\n",
    "# Guided Backprob\n",
    "attr_gbp_lungCT = []\n",
    "for model in (model_lungCT_a, model_lungCT_b):\n",
    "    attr_method = NoiseTunnel(GuidedBackprop(TwoHead_Wrapper(model)))\n",
    "    for target in (0, 1):\n",
    "        attr_values = attr_method.attribute(\n",
    "            data_lungCT[n].unsqueeze(0),\n",
    "            target=target,\n",
    "            stdevs=stdevs,\n",
    "            nt_type=nt_type,\n",
    "            nt_samples=nt_samples,\n",
    "            nt_samples_batch_size=nt_samples_batch_size,\n",
    "        )\n",
    "        attr_gbp_lungCT.append(normalize_pos_neg(attr_values.squeeze(0)))\n",
    "\n",
    "for model in (model_lungCT_a, model_lungCT_b):\n",
    "    attr_method = NoiseTunnel(GuidedBackprop(CATE_Wrapper(model)))\n",
    "    attr_values = attr_method.attribute(\n",
    "        data_lungCT[n].unsqueeze(0),\n",
    "        target=0,\n",
    "        stdevs=stdevs,\n",
    "        nt_type=nt_type,\n",
    "        nt_samples=nt_samples,\n",
    "        nt_samples_batch_size=nt_samples_batch_size,\n",
    "    )\n",
    "    attr_gbp_lungCT.append(normalize_pos_neg(attr_values.squeeze(0)))\n",
    "\n",
    "attr_gbp_lungCT = [attr_gbp_lungCT[i] for i in [0, 1, 4, 2, 3, 5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fdefd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "attr_type = [\n",
    "    \"EG\",\n",
    "    \"IG\",\n",
    "    \"GCAM\",\n",
    "    \"GGCAM\",\n",
    "]\n",
    "model_type = [\n",
    "    \"TwoHead_0_a\",\n",
    "    \"TwoHead_1_a\",\n",
    "    \"CATE_a\",\n",
    "    \"TwoHead_0_b\",\n",
    "    \"TwoHead_1_b\",\n",
    "    \"CATE_b\",\n",
    "]\n",
    "\n",
    "if not os.path.exists(\"./Images/lungCT/\" + str(n) + \"/\"):\n",
    "    os.makedirs(\"./Images/lungCT/\" + str(n) + \"/\")\n",
    "\n",
    "norm = [0.2, 0.15, None, 0.05]\n",
    "vmin = -1150\n",
    "vmax = 550\n",
    "\n",
    "attr_ggcam_lungCT = [\n",
    "    normalize_pos_neg(torch.Tensor(np.moveaxis(a[None, :], 3, 1)) * b.cpu())\n",
    "    for a, b in zip(attr_gcam_lungCT, attr_gbp_lungCT)\n",
    "]\n",
    "\n",
    "for idx, attr in enumerate(\n",
    "    [attr_eg_lungCT, attr_ig_lungCT, attr_gcam_lungCT, attr_ggcam_lungCT]\n",
    "):\n",
    "    img = np.transpose(data_lungCT[n, 0].cpu().detach().numpy(), (1, 2, 0))\n",
    "    img = (img - vmin) / (vmax - vmin)\n",
    "    img = np.clip(img, 0, 1)\n",
    "\n",
    "    first = np.where(img.mean((0, 1)) > img.mean((0, 1))[0])[0][0]\n",
    "    last = np.where(img.mean((0, 1)) > img.mean((0, 1))[0])[0][-1]\n",
    "    dist = last - first\n",
    "    step = 2 if dist <= 10 else 4\n",
    "\n",
    "    for model in range(6):\n",
    "        if idx == 2:\n",
    "            fig, axes = plt.subplots(\n",
    "                2,\n",
    "                int(np.ceil((dist) / step)),\n",
    "                figsize=(int(np.ceil((dist) / step)) * 2, 3),\n",
    "                sharey=True,\n",
    "                sharex=True,\n",
    "            )\n",
    "\n",
    "            for i, slice in enumerate(list(range(first, last, step))):\n",
    "                img = np.transpose(\n",
    "                    data_lungCT[n, :, slice].cpu().detach().numpy(), (1, 2, 0)\n",
    "                )\n",
    "                img = (img - vmin) / (vmax - vmin)\n",
    "                img = np.clip(img, 0, 1)\n",
    "                img = np.repeat(img, 3, axis=2)\n",
    "\n",
    "                gcam_vis = show_cam_on_image(\n",
    "                    img, attr[model][:, :, slice], use_rgb=True\n",
    "                )\n",
    "\n",
    "                if seg_lungCT[n, 0, slice].sum() > 0:\n",
    "                    contours, im = cv2.findContours(\n",
    "                        seg_lungCT[n, 0, slice], cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE\n",
    "                    )\n",
    "                    cv2.drawContours(img, contours, -1, (1, 0.525, 0), 2)\n",
    "\n",
    "                axes[0, i].imshow(img)\n",
    "                axes[0, i].axis(\"off\")\n",
    "                axes[0, i].set_title(\"Slice: \" + str(slice), fontsize=10)\n",
    "                axes[1, i].imshow(gcam_vis)\n",
    "                axes[1, i].axis(\"off\")\n",
    "\n",
    "            plt.tight_layout()\n",
    "        else:\n",
    "            fig, axes = plt.subplots(\n",
    "                2,\n",
    "                int(np.ceil((dist) / step)),\n",
    "                figsize=(int(np.ceil((dist) / step)) * 2, 3),\n",
    "                sharey=True,\n",
    "                sharex=True,\n",
    "            )\n",
    "\n",
    "            for i, slice in enumerate(list(range(first, last, step))):\n",
    "                img = np.transpose(\n",
    "                    data_lungCT[n, :, slice].cpu().detach().numpy(), (1, 2, 0)\n",
    "                )\n",
    "                img = (img - vmin) / (vmax - vmin)\n",
    "                img = np.clip(img, 0, 1)\n",
    "                img = np.repeat(img, 3, axis=2)\n",
    "\n",
    "                if seg_lungCT[n, 0, slice].sum() > 0:\n",
    "                    contours, im = cv2.findContours(\n",
    "                        seg_lungCT[n, 0, slice], cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE\n",
    "                    )\n",
    "                    cv2.drawContours(img, contours, -1, (1, 0.525, 0), 2)\n",
    "\n",
    "                axes[0, i].imshow(img)\n",
    "                axes[0, i].axis(\"off\")\n",
    "                axes[0, i].set_title(\"Slice: \" + str(slice), fontsize=10)\n",
    "\n",
    "                vis.visualize_image_attr(\n",
    "                    np.where(\n",
    "                        np.abs(\n",
    "                            np.transpose(\n",
    "                                attr[model][:, slice].cpu().detach().numpy(), (1, 2, 0)\n",
    "                            )\n",
    "                        )\n",
    "                        < norm[idx],\n",
    "                        0,\n",
    "                        np.transpose(\n",
    "                            attr[model][:, slice].cpu().detach().numpy(), (1, 2, 0)\n",
    "                        ),\n",
    "                    ),\n",
    "                    img,\n",
    "                    \"heat_map\",\n",
    "                    \"all\",\n",
    "                    plt_fig_axis=(fig, axes[1, i]),\n",
    "                    cmap=heat_cmap,\n",
    "                    show_colorbar=False,\n",
    "                    use_pyplot=False,\n",
    "                )\n",
    "\n",
    "                axes[1, i].axis(\"off\")\n",
    "\n",
    "        plt._original_dpi = 200 if dist <= 10 else 300\n",
    "\n",
    "        plt.savefig(\n",
    "            \"./Images/lungCT/\"\n",
    "            + str(n)\n",
    "            + \"/\"\n",
    "            + str(attr_type[idx])\n",
    "            + \"_\"\n",
    "            + model_type[model]\n",
    "            + \".png\",\n",
    "            bbox_inches=\"tight\",\n",
    "            pad_inches=0,\n",
    "        )\n",
    "        plt.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "db7a9d26",
   "metadata": {},
   "source": [
    "#### Single Slice Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ad330c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "attr_type = [\"GCAM\", \"GGCAM\"]\n",
    "model_type = [\n",
    "    \"TwoHead_0_a\",\n",
    "    \"TwoHead_1_a\",\n",
    "    \"CATE_a\",\n",
    "    \"TwoHead_0_b\",\n",
    "    \"TwoHead_1_b\",\n",
    "    \"CATE_b\",\n",
    "]\n",
    "\n",
    "if not os.path.exists(\"./Images/lungCT/\" + str(n) + \"/\"):\n",
    "    os.makedirs(\"./Images/lungCT/\" + str(n) + \"/\")\n",
    "\n",
    "norm = [None, 0.09]\n",
    "vmin = -1150\n",
    "vmax = 550\n",
    "\n",
    "attr_ggcam_lungCT = [\n",
    "    normalize_pos_neg(torch.Tensor(np.moveaxis(a[None, :], 3, 1)) * b.cpu())\n",
    "    for a, b in zip(attr_gcam_lungCT, attr_gbp_lungCT)\n",
    "]\n",
    "\n",
    "slice = 23\n",
    "\n",
    "img = np.transpose(data_lungCT[n, :, slice].cpu().detach().numpy(), (1, 2, 0))\n",
    "img = (img - vmin) / (vmax - vmin)\n",
    "img = np.clip(img, 0, 1)\n",
    "img = np.repeat(img, 3, axis=2)\n",
    "contours, im = cv2.findContours(\n",
    "    seg_lungCT[n, 0, slice], cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE\n",
    ")\n",
    "cv2.drawContours(img, contours, -1, (1, 0.525, 0), 2)\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "\n",
    "plt._original_dpi = 200\n",
    "\n",
    "plt.savefig(\n",
    "    \"./Images/lungCT/\" + str(n) + \"/Slice_\" + str(slice) + \".png\",\n",
    "    bbox_inches=\"tight\",\n",
    "    pad_inches=0,\n",
    ")\n",
    "plt.close()\n",
    "\n",
    "for model in range(3):\n",
    "    for idx, attr in enumerate([attr_gcam_lungCT, attr_ggcam_lungCT]):\n",
    "        if idx == 0:\n",
    "            img = np.transpose(\n",
    "                data_lungCT[n, :, slice].cpu().detach().numpy(), (1, 2, 0)\n",
    "            )\n",
    "            img = (img - vmin) / (vmax - vmin)\n",
    "            img = np.clip(img, 0, 1)\n",
    "            img = np.repeat(img, 3, axis=2)\n",
    "\n",
    "            gcam_vis = show_cam_on_image(img, attr[model][:, :, slice], use_rgb=True)\n",
    "\n",
    "            plt.imshow(gcam_vis)\n",
    "\n",
    "            plt.axis(\"off\")\n",
    "            plt.tight_layout()\n",
    "            plt._original_dpi = 200\n",
    "\n",
    "            plt.savefig(\n",
    "                \"./Images/lungCT/\"\n",
    "                + str(n)\n",
    "                + \"/Slice_\"\n",
    "                + str(slice)\n",
    "                + \"_\"\n",
    "                + attr_type[idx]\n",
    "                + \"_\"\n",
    "                + model_type[model]\n",
    "                + \".png\",\n",
    "                bbox_inches=\"tight\",\n",
    "                pad_inches=0,\n",
    "            )\n",
    "            plt.close()\n",
    "        else:\n",
    "            img = np.transpose(\n",
    "                data_lungCT[n, :, slice].cpu().detach().numpy(), (1, 2, 0)\n",
    "            )\n",
    "            img = (img - vmin) / (vmax - vmin)\n",
    "            img = np.clip(img, 0, 1)\n",
    "            img = np.repeat(img, 3, axis=2)\n",
    "\n",
    "            fig, ax = vis.visualize_image_attr(\n",
    "                np.where(\n",
    "                    np.abs(\n",
    "                        np.transpose(\n",
    "                            attr[model][:, slice].cpu().detach().numpy(), (1, 2, 0)\n",
    "                        )\n",
    "                    )\n",
    "                    < norm[idx],\n",
    "                    0,\n",
    "                    np.transpose(\n",
    "                        attr[model][:, slice].cpu().detach().numpy(), (1, 2, 0)\n",
    "                    ),\n",
    "                ),\n",
    "                img,\n",
    "                \"heat_map\",\n",
    "                \"all\",\n",
    "                cmap=heat_cmap,\n",
    "                show_colorbar=False,\n",
    "                use_pyplot=False,\n",
    "            )\n",
    "\n",
    "            ax.axis(\"off\")\n",
    "            fig.tight_layout()\n",
    "            fig._original_dpi = 100\n",
    "\n",
    "            fig.savefig(\n",
    "                \"./Images/lungCT/\"\n",
    "                + str(n)\n",
    "                + \"/Slice_\"\n",
    "                + str(slice)\n",
    "                + \"_\"\n",
    "                + attr_type[idx]\n",
    "                + \"_\"\n",
    "                + model_type[model]\n",
    "                + \".png\",\n",
    "                bbox_inches=\"tight\",\n",
    "                pad_inches=0,\n",
    "            )\n",
    "            plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "64b348821e553da718e83388c56cb0dce57aa897dd0ce1bda2994304956044f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
